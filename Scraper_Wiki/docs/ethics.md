# Web Scraping Ethics

This project respects the legal and ethical boundaries of data collection. When scraping any website you must:

- **Check `robots.txt`** and comply with the site's crawling rules.
- **Rate limit requests** to avoid overwhelming remote servers.
- Identify yourself with a User-Agent header and provide contact information when possible.
- Store only publicly available content and honor takedown requests.

Failure to follow these practices can lead to legal issues or banned IPs. Always verify the licensing terms of the data source before distributing any dataset derived from it.
